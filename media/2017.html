<!DOCTYPE html>
<html lang="en">
  <head>

    <script
      src="https://code.jquery.com/jquery-3.3.1.js"
      integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60="
      crossorigin="anonymous">
    </script>
    <script src="/js/template.js"></script>

    
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <title>
      PLOrk - 2017
    </title>
    <meta name="author" content="">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/css/tachyons.css">

    <!-- stylesheet linking for playlist -->
    <!-- <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.1/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous"> -->
    <link rel="stylesheet" href="/css/playlist.css">

  </head>
  <body class="bg-black-5 black-70 pa4 sans-serif">
  
    <header></header><script>getHeader()</script>

    <<h1 class="ml2 mt0 mb4 f-headline-l">PLOrk : 2017 : 10th Anniversary Show</h1>

    <div class="vid-container">
      <iframe id="vid_frame" width="100%" height="700vw" src="https://www.youtube.com/embed/videoseries?list=PLSDFnXBp2a4nq3OkMtbTddQKOFfMtly_l&index=0&autoplay=1" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </div>

    <div class="vid-list-container">
      <div class ="vid-list">

        <div class="vid-item" onClick="document.getElementById('vid_frame').src='https://www.youtube.com/embed/videoseries?list=PLSDFnXBp2a4nq3OkMtbTddQKOFfMtly_l&index=0&autoplay=1'">
          <div class="thumb">
            <img src="https://img.youtube.com/vi/Q_Us12Q4res/0.jpg" alt="" />
          </div>
          <div class="desc">
            Past Strands 
          </div>
        </div>

        <div class="vid-item" onClick="document.getElementById('vid_frame').src='https://www.youtube.com/embed/videoseries?list=PLSDFnXBp2a4nq3OkMtbTddQKOFfMtly_l&index=1&autoplay=1'">
          <div class="thumb">
            <img src="https://img.youtube.com/vi/IEev6pBMmyI/0.jpg" alt="" />
          </div>
          <div class="desc">
            Connectome
          </div>
        </div>

        <div class="vid-item" onClick="document.getElementById('vid_frame').src='https://www.youtube.com/embed/videoseries?list=PLSDFnXBp2a4nq3OkMtbTddQKOFfMtly_l&index=2&autoplay=1'">
          <div class="thumb">
            <img src="https://img.youtube.com/vi/pzHOXHrqqlg/0.jpg" alt="" />
          </div>
          <div class="desc">
            Holy Mountain
          </div>
        </div>

        <div class="vid-item" onClick="document.getElementById('vid_frame').src='https://www.youtube.com/embed/videoseries?list=PLSDFnXBp2a4nq3OkMtbTddQKOFfMtly_l&index=3&autoplay=1'">
          <div class="thumb">
            <img src="https://img.youtube.com/vi/IZ6LWVTahLY/0.jpg" alt="" />
          </div>
          <div class="desc">
            My God It's Full of Stars
          </div>
        </div>

        <div class="vid-item" onClick="document.getElementById('vid_frame').src='https://www.youtube.com/embed/videoseries?list=PLSDFnXBp2a4nq3OkMtbTddQKOFfMtly_l&index=4&autoplay=1'">
          <div class="thumb">
            <img src="https://img.youtube.com/vi/G778-ELNuQQ/0.jpg" alt="" />
          </div>
          <div class="desc">
            Ndivumbamirewo + Nyong'o
          </div>
        </div>

      </div>
    </div>

    <!-- LEFT AND RIGHT ARROWS -->
    <!-- 
    <div class="arrows">
      <div class="arrow-left"><i class="fa fa-chevron-left fa-lg"></i></div>
      <div class="arrow-right"><i class="fa fa-chevron-right fa-lg"></i></div>
    </div>
    
    <script type="text/javascript">
      $(document).ready(function () {
        $(".arrow-right").bind("click", function (event) {
            event.preventDefault();
            $(".vid-list-container").stop().animate({
                scrollLeft: "+=336"
            }, 750);
        });
        $(".arrow-left").bind("click", function (event) {
            event.preventDefault();
            $(".vid-list-container").stop().animate({
                scrollLeft: "-=336"
            }, 750);
        });
    });
    </script>
    -->
    
    <h2 class="">Taplin Auditorium 8pm May 3rd, 2017</h2>

    <dl class="lh-title pa4 mt0">
      <dt class="f5 b">Director</dt>
      <dd class="ml0">Jeff Snyder</dd>
      <dt class="f5 b mt2">Associate Director</dt>
      <dd class="ml0">Jason Treuting</dd>
      <dt class="f5 b mt2">Assistant Director</dt>
      <dd class="ml0">Mike Mulshine</dd>
    </dl>

    <dl class="lh-title pa4 mt0">
      <dt class="f5 b">Ensemble</dt>
      <dd class="ml0">Jenny Beck</dd>
      <dd class="ml0">Josh Becker</dd>
      <dd class="ml0">Alex Cavoli</dd>
      <dd class="ml0">Chris Douthitt</dd>
      <dd class="ml0">Florent Ghys</dd> 
      <dd class="ml0">Catherine Lu</dd> 
      <dd class="ml0">Matt McBane</dd> 
      <dd class="ml0">Avneesh Sarwate</dd>
      <dd class="ml0">Nikitas Tampakis</dd>
      <dd class="ml0">Crystal Qian</dd> 
      <dd class="ml0">Matt Wang</dd>
    </dl>

    <dl class="lh-title pa4 mt0">
      <dt class="f5 b">Special Guests</dt>
      <dd class="ml0">HPrizm (a.k.a. High Priest of Anti-pop Consortium)</dd>
      <dd class="ml0">Iarla Ó Lionáird</dd>
      <dd class="ml0">Eric Cha-Beach</dd>
      <dd class="ml0">Adam Sliwinski</dd>
    </dl>

    <!-- PAST STRANDS -->
    <dl class="lh-title pa4 mt0">
      <dt class="f4 b">Past Strands</dt>
      <dd class="ml0">by PLOrk</dd><br>

      <dd class="ml3 i">This piece grew out of PLOrk member Josh Becker’s final project for MUS/COS314, (Electronic and Computer Music I). Josh developed a software instrument that uses complicated feedback between multiple oscillators to create unstable but fascinating textures. The instrument design included a visual component that created shapes, called “Lissajous figures” from the audio waveform. In exploring how we might use the instrument in performance, we hit upon the idea of performing some music from the Renaissance as a quartet. Three PLOrk members, Josh, Matthew, and Catherine, are all in Dmitri Tymoczko’s MUS315 course this semester, which is focused on algorithmic composition and computational musicology. They decided to create an algorithmically altered version of a Renaissance piece, using the techniques they learned in Tymoczko’s course. Then, Josh asked the question “What if instead of projecting the images, we used lasers?”  Indeed, WHAT IF WE USED LASERS?????</dd>

    </dl>

    <!-- CONNECTOME -->
    <dl class="lh-title pa4 mt0">
      <dt class="f4 b">Connectome</dt>
      <dd class="ml0">music by PLOrk</dd>
      <dd class="ml0">visuals by Drew Wallace</dd><br>

      <dd class="ml3 i">This piece came about based on an idea floated by PLOrk alum and electrical engineering PhD student Mitch Nahmias a couple of years ago. The lab he works in, the Lightwave Communications Research Laboratory, uses what are called “biological models” of neurons – bits of computer code that are designed to behave the way a neuron would in a brain. They spike in response to certain inputs, and then settle, with a particular pattern and shape to this curve. Some conditions cause oscillatory behavior, where the spikes repeat at some frequency, as they do in an animal brain. He mentioned this to me, and suggested that we try using one of those models to make sound. </dd>

      <dd class="ml3 i">Now, a couple of years later, we’ve built a piece around this idea. Aatish Bhatia of the Council for Science and Technology joined the project, and he figured out how to discretize the model (so that it could be run in real-time on a computer). From there, I built a software instrument using this new synthesis technique, and Assistant Director Mike Mulshine wrapped that code into a handy package and composed the musical structure for the piece.  Drew Wallace, a senior in Computer Science and Visual Arts, created the live visualization, which represents each performer as a neuron-like object and shows how we are “connected” to each other (which changes throughout the piece).</dd>

      <dd class="ml3 i">The instrument itself is interesting and unpredictable. Unlike most electronic musical instruments, in which the controls represent parameters that are meaningful to humans (like “pitch, amplitude, brightness”), this instrument has parameters that are actually quite anti-intuitive to us. We have a knob for the sodium activation channel, another for the potassium channel, another for the capacitance of the system, and so on. These parameters interact in strange ways, and we have been slowly learning to play this instrument by experimenting with these interactions. </dd>

      <dd class="ml3 i">A couple of curious asides: the biological model on which we built our instrument is actually a model of a giant squid axon, since apparently that was the only animal with neurons large enough that measurements could be easily taken on single neurons in the 1950’s, when the model was developed. Also, the moment when we all synchronize is what is happening during a seizure.</dd>
    </dl>

    <!-- HOLY MOUNTAIN -->
    <dl class="lh-title pa4 mt0">
      <dt class="f4 b">Holy Mountain</dt>
      <dd class="ml0">music by HPrizm and PLOrk</dd>
      <dd class="ml0">video by Eric Hayes and Jeff Snyder</dd><br></br>

      <dd class="ml3 i">This piece developed as a collaboration between our guest artist Hprizm and the group. HPrizm had the idea to do something using cut-up video of a dance performance, controlled by the music performers. Around that time, Computer Science student and filmmaker Eric Hayes contacted me about advising him on a junior project, and I roped him into doing the video development for this piece. Eric was interested in using the motion capture system in the Council for Science and Technology’s Studiolab, and he designed some wearable markers so that he could track the movements of several points on a dancer’s body. He recorded captures of several dancers from different stylistic backgrounds, from modern dance to hip-hop, and created a system that visualizes this data and allows the musicians to control and interact with the visuals. HPrizm had the idea to integrate things one step further, by using the data from the motion capture to control the musicians’ audio parameters as well, so we can use the curve of a dancer’s hand motion and apply that shape to a filter sweep, for instance.</dd>

      <dd class="ml3 i">Three of the performers in this piece are playing on analog modular synthesizers, using a sequencer interface called the MantaMate, which was developed over the past few years by the performers playing it, Snyder, Becker, and Mulshine. Other Princeton students who have been involved in the development of the MantaMate include Elaine Chou, YC Sun, and Chloe Song, all supported by funding from the Keller Center.</dd>

      <br></br>

      <dt class="f6 b">Motion-captured dancers:</dt>
      <dd class="ml0">Anna Kimmel '18</dd>
      <dd class="ml0">Raheem Barnett '18</dd>
      <dd class="ml0">Dorothy Chen '17</dd>
      <dd class="ml0">Lauren Auyeung '19</dd>
    </dl>

    <!-- MY GOD ITS FULL OF STARS -->
    <dl class="lh-title pa4 mt0">
      <dt class="f4 b">My God It’s Full of Stars</dt>
      <dd class="ml0">poem by Tracy K. Smith</dd>
      <dd class="ml0">arranged by PLOrk and HPrizm</dd><br/>

      <dd class="ml3 i">This piece was inspired by a poem written by Princeton creative writing professor Tracy K. Smith. Iarla, an Irish folk singer who is joining us as a guest artist, loved the poem, and wanted to do a piece that responded to its celestial themes. Priest wrote his own verse in response to the poem, and we built a piece around these contributions. PLOrk members and composition PhD students Florent Ghys and Chris Douthitt handled the compositional and arrangement duties to bring form to the floating ideas that were coalescing among the group.</dd><br></br>
      <dd class="ml3 i">Here’s the poem, the third section of Smith’s My God It’s Full Of Stars:</dd><br/>
      <dd class="ml4"> 
        Perhaps the great error is believing we’re alone,  <br/>
        That the others have come and gone—a momentary blip—  <br/>
        When all along, space might be choc-full of traffic,  <br/>
        Bursting at the seams with energy we neither feel  <br/>
        Nor see, flush against us, living, dying, deciding,  <br/>
        Setting solid feet down on planets everywhere,  <br/>
        Bowing to the great stars that command, pitching stones  <br/>
        At whatever are their moons. They live wondering  <br/>
        If they are the only ones, knowing only the wish to know,  <br/>
        And the great black distance they—we—flicker in.  <br/></dd><br/>

      <dd class="ml4">
        Maybe the dead know, their eyes widening at last,  <br/>
        Seeing the high beams of a million galaxies flick on  <br/>
        At twilight. Hearing the engines flare, the horns  <br/>
        Not letting up, the frenzy of being. I want to be  <br/>
        One notch below bedlam, like a radio without a dial.  <br/>
        Wide open, so everything floods in at once.  <br/>
        And sealed tight, so nothing escapes. Not even time,  <br/>
        Which should curl in on itself and loop around like smoke.  <br/>
        So that I might be sitting now beside my father  <br/>
        As he raises a lit match to the bowl of his pipe  <br/>
        For the first time in the winter of 1959.  <br/></dd>

    </dl>

    <!-- OPPOSITE EARTH -->
    <dl class="lh-title pa4 mt0">
      <dt class="f4 b">Ndivumbamirewo + Nyong’o</dt>
      <dd class="ml0">by Marshall Munhumumwe and the Four Brother</dd>
      <dd class="ml0">transcribed by Florent Ghys</dd>
      <dd class="ml0">arranged by PLOrk</dd><br>

      <dd class="ml3 i">Florent Ghys brought in this piece, which he transcribed from a recording by the Zimbabwean pop group the Four Brothers. Our arrangement takes a lot of liberties with it, but we think it maintains the spirit of the original tune. There are two new digital instruments developed by PLOrk members that we are using to realize our version. One of them is a live coding environment designed by Avneesh Sarwate, which allows the performers to record incoming audio and then re-arrange it into complex rhythms through a simple syntax built on the computer language Python.  The other was developed by graduate composer Chris Douthitt as a project for Kofi Agawu’s African Music course. Douthitt’s software uses the concept of expressing rhythms as “inter-onset intervals”, the time between the beginnings or attack points of successive events or notes, which is a common way to describe African bell patterns. The software allows the performers to define two rhythmic patterns in this notation, and then “drift” between them, interpolating where the beats should occur as the rhythms morph into each other. </dd>

    </dl>

    <footer></footer><script>getFooter()</script>
    
  </body>
</html>
